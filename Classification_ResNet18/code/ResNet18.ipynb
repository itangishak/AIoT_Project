{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CDNWpzDGOnV"
      },
      "outputs": [],
      "source": [
        "#this to test if it works very well\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On0EKQRYGOnX"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, inchannel, outchannel, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.left = nn.Sequential(\n",
        "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(outchannel),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(outchannel)\n",
        "        )\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or inchannel != outchannel:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(outchannel)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.left(x)\n",
        "        out = out + self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, ResidualBlock, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inchannel = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer1 = self.make_layer(ResidualBlock, 64, 2, stride=1)\n",
        "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
        "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n",
        "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def make_layer(self, block, channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.inchannel, channels, stride))\n",
        "            self.inchannel = channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeTYPCTgGOnY"
      },
      "outputs": [],
      "source": [
        "def ResNet18():\n",
        "    return ResNet(ResidualBlock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIK2F0F5GOnZ",
        "outputId": "9390b027-1052-4936-bd66-9c1515286aac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:08<00:00, 1.13MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 104kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 910kB/s] \n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 807kB/s]\n"
          ]
        }
      ],
      "source": [
        "#Use the ResNet18 on MNIST\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "#check gpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#set hyperparameter\n",
        "EPOCH = 10\n",
        "pre_epoch = 0\n",
        "BATCH_SIZE = 128\n",
        "LR = 0.01\n",
        "\n",
        "#prepare dataset and preprocessing (MNIST -> make 3x32x32 to match network)\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize(32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize(32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='../data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='../data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "#labels in MNIST\n",
        "classes = tuple(str(i) for i in range(10))\n",
        "\n",
        "#define ResNet18\n",
        "net = ResNet18().to(device)\n",
        "\n",
        "#define loss funtion & optimize\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh9Xz5wSGOna",
        "outputId": "40aff4e6-7b34-4565-9aa4-a399f9432359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n",
            "[epoch:1, iter:1] Loss: 2.550 | Acc: 7.031% \n",
            "[epoch:1, iter:2] Loss: 2.428 | Acc: 12.891% \n",
            "[epoch:1, iter:3] Loss: 2.341 | Acc: 16.406% \n",
            "[epoch:1, iter:4] Loss: 2.279 | Acc: 18.945% \n",
            "[epoch:1, iter:5] Loss: 2.233 | Acc: 20.625% \n",
            "[epoch:1, iter:6] Loss: 2.195 | Acc: 21.354% \n",
            "[epoch:1, iter:7] Loss: 2.130 | Acc: 24.554% \n",
            "[epoch:1, iter:8] Loss: 2.065 | Acc: 27.246% \n",
            "[epoch:1, iter:9] Loss: 1.990 | Acc: 31.424% \n",
            "[epoch:1, iter:10] Loss: 1.947 | Acc: 33.438% \n",
            "[epoch:1, iter:11] Loss: 1.893 | Acc: 35.582% \n",
            "[epoch:1, iter:12] Loss: 1.841 | Acc: 37.695% \n",
            "[epoch:1, iter:13] Loss: 1.781 | Acc: 40.084% \n",
            "[epoch:1, iter:14] Loss: 1.716 | Acc: 42.522% \n",
            "[epoch:1, iter:15] Loss: 1.649 | Acc: 45.365% \n",
            "[epoch:1, iter:16] Loss: 1.599 | Acc: 47.314% \n",
            "[epoch:1, iter:17] Loss: 1.543 | Acc: 49.311% \n",
            "[epoch:1, iter:18] Loss: 1.487 | Acc: 51.476% \n",
            "[epoch:1, iter:19] Loss: 1.435 | Acc: 53.413% \n",
            "[epoch:1, iter:20] Loss: 1.389 | Acc: 55.195% \n",
            "[epoch:1, iter:21] Loss: 1.343 | Acc: 56.585% \n",
            "[epoch:1, iter:22] Loss: 1.300 | Acc: 57.884% \n",
            "[epoch:1, iter:23] Loss: 1.260 | Acc: 59.205% \n",
            "[epoch:1, iter:24] Loss: 1.221 | Acc: 60.514% \n",
            "[epoch:1, iter:25] Loss: 1.184 | Acc: 61.750% \n",
            "[epoch:1, iter:26] Loss: 1.150 | Acc: 62.831% \n",
            "[epoch:1, iter:27] Loss: 1.121 | Acc: 63.918% \n",
            "[epoch:1, iter:28] Loss: 1.089 | Acc: 65.011% \n",
            "[epoch:1, iter:29] Loss: 1.058 | Acc: 66.002% \n",
            "[epoch:1, iter:30] Loss: 1.029 | Acc: 66.953% \n",
            "[epoch:1, iter:31] Loss: 1.000 | Acc: 67.969% \n",
            "[epoch:1, iter:32] Loss: 0.974 | Acc: 68.823% \n",
            "[epoch:1, iter:33] Loss: 0.950 | Acc: 69.602% \n",
            "[epoch:1, iter:34] Loss: 0.928 | Acc: 70.312% \n",
            "[epoch:1, iter:35] Loss: 0.905 | Acc: 71.071% \n",
            "[epoch:1, iter:36] Loss: 0.884 | Acc: 71.766% \n",
            "[epoch:1, iter:37] Loss: 0.868 | Acc: 72.297% \n",
            "[epoch:1, iter:38] Loss: 0.849 | Acc: 72.862% \n",
            "[epoch:1, iter:39] Loss: 0.833 | Acc: 73.417% \n",
            "[epoch:1, iter:40] Loss: 0.815 | Acc: 73.965% \n",
            "[epoch:1, iter:41] Loss: 0.799 | Acc: 74.486% \n",
            "[epoch:1, iter:42] Loss: 0.785 | Acc: 74.963% \n",
            "[epoch:1, iter:43] Loss: 0.769 | Acc: 75.436% \n",
            "[epoch:1, iter:44] Loss: 0.755 | Acc: 75.923% \n",
            "[epoch:1, iter:45] Loss: 0.741 | Acc: 76.354% \n",
            "[epoch:1, iter:46] Loss: 0.727 | Acc: 76.800% \n",
            "[epoch:1, iter:47] Loss: 0.715 | Acc: 77.178% \n",
            "[epoch:1, iter:48] Loss: 0.702 | Acc: 77.588% \n",
            "[epoch:1, iter:49] Loss: 0.689 | Acc: 77.997% \n",
            "[epoch:1, iter:50] Loss: 0.680 | Acc: 78.312% \n",
            "[epoch:1, iter:51] Loss: 0.671 | Acc: 78.615% \n",
            "[epoch:1, iter:52] Loss: 0.661 | Acc: 78.966% \n",
            "[epoch:1, iter:53] Loss: 0.650 | Acc: 79.319% \n",
            "[epoch:1, iter:54] Loss: 0.642 | Acc: 79.601% \n",
            "[epoch:1, iter:55] Loss: 0.632 | Acc: 79.886% \n",
            "[epoch:1, iter:56] Loss: 0.624 | Acc: 80.176% \n",
            "[epoch:1, iter:57] Loss: 0.615 | Acc: 80.469% \n",
            "[epoch:1, iter:58] Loss: 0.606 | Acc: 80.752% \n",
            "[epoch:1, iter:59] Loss: 0.597 | Acc: 81.025% \n",
            "[epoch:1, iter:60] Loss: 0.590 | Acc: 81.289% \n",
            "[epoch:1, iter:61] Loss: 0.581 | Acc: 81.545% \n",
            "[epoch:1, iter:62] Loss: 0.574 | Acc: 81.779% \n",
            "[epoch:1, iter:63] Loss: 0.567 | Acc: 82.031% \n",
            "[epoch:1, iter:64] Loss: 0.560 | Acc: 82.263% \n",
            "[epoch:1, iter:65] Loss: 0.553 | Acc: 82.500% \n",
            "[epoch:1, iter:66] Loss: 0.546 | Acc: 82.730% \n",
            "[epoch:1, iter:67] Loss: 0.539 | Acc: 82.952% \n",
            "[epoch:1, iter:68] Loss: 0.532 | Acc: 83.203% \n",
            "[epoch:1, iter:69] Loss: 0.525 | Acc: 83.413% \n",
            "[epoch:1, iter:70] Loss: 0.519 | Acc: 83.605% \n",
            "[epoch:1, iter:71] Loss: 0.513 | Acc: 83.814% \n",
            "[epoch:1, iter:72] Loss: 0.507 | Acc: 84.017% \n",
            "[epoch:1, iter:73] Loss: 0.502 | Acc: 84.161% \n",
            "[epoch:1, iter:74] Loss: 0.497 | Acc: 84.312% \n",
            "[epoch:1, iter:75] Loss: 0.491 | Acc: 84.500% \n",
            "[epoch:1, iter:76] Loss: 0.486 | Acc: 84.683% \n",
            "[epoch:1, iter:77] Loss: 0.481 | Acc: 84.842% \n",
            "[epoch:1, iter:78] Loss: 0.476 | Acc: 84.996% \n",
            "[epoch:1, iter:79] Loss: 0.471 | Acc: 85.166% \n",
            "[epoch:1, iter:80] Loss: 0.466 | Acc: 85.322% \n",
            "[epoch:1, iter:81] Loss: 0.461 | Acc: 85.465% \n",
            "[epoch:1, iter:82] Loss: 0.456 | Acc: 85.604% \n",
            "[epoch:1, iter:83] Loss: 0.452 | Acc: 85.730% \n",
            "[epoch:1, iter:84] Loss: 0.448 | Acc: 85.872% \n",
            "[epoch:1, iter:85] Loss: 0.443 | Acc: 86.020% \n",
            "[epoch:1, iter:86] Loss: 0.439 | Acc: 86.146% \n",
            "[epoch:1, iter:87] Loss: 0.434 | Acc: 86.288% \n",
            "[epoch:1, iter:88] Loss: 0.431 | Acc: 86.399% \n",
            "[epoch:1, iter:89] Loss: 0.428 | Acc: 86.491% \n",
            "[epoch:1, iter:90] Loss: 0.423 | Acc: 86.632% \n",
            "[epoch:1, iter:91] Loss: 0.420 | Acc: 86.736% \n",
            "[epoch:1, iter:92] Loss: 0.417 | Acc: 86.863% \n",
            "[epoch:1, iter:93] Loss: 0.413 | Acc: 86.971% \n",
            "[epoch:1, iter:94] Loss: 0.410 | Acc: 87.084% \n",
            "[epoch:1, iter:95] Loss: 0.409 | Acc: 87.113% \n",
            "[epoch:1, iter:96] Loss: 0.405 | Acc: 87.223% \n",
            "[epoch:1, iter:97] Loss: 0.403 | Acc: 87.323% \n",
            "[epoch:1, iter:98] Loss: 0.400 | Acc: 87.404% \n",
            "[epoch:1, iter:99] Loss: 0.397 | Acc: 87.500% \n",
            "[epoch:1, iter:100] Loss: 0.395 | Acc: 87.562% \n",
            "[epoch:1, iter:101] Loss: 0.391 | Acc: 87.670% \n",
            "[epoch:1, iter:102] Loss: 0.389 | Acc: 87.745% \n",
            "[epoch:1, iter:103] Loss: 0.386 | Acc: 87.834% \n",
            "[epoch:1, iter:104] Loss: 0.383 | Acc: 87.928% \n",
            "[epoch:1, iter:105] Loss: 0.380 | Acc: 88.021% \n",
            "[epoch:1, iter:106] Loss: 0.377 | Acc: 88.119% \n",
            "[epoch:1, iter:107] Loss: 0.374 | Acc: 88.208% \n",
            "[epoch:1, iter:108] Loss: 0.372 | Acc: 88.296% \n",
            "[epoch:1, iter:109] Loss: 0.369 | Acc: 88.389% \n",
            "[epoch:1, iter:110] Loss: 0.367 | Acc: 88.459% \n",
            "[epoch:1, iter:111] Loss: 0.364 | Acc: 88.549% \n",
            "[epoch:1, iter:112] Loss: 0.361 | Acc: 88.637% \n",
            "[epoch:1, iter:113] Loss: 0.358 | Acc: 88.717% \n",
            "[epoch:1, iter:114] Loss: 0.356 | Acc: 88.802% \n",
            "[epoch:1, iter:115] Loss: 0.353 | Acc: 88.879% \n",
            "[epoch:1, iter:116] Loss: 0.351 | Acc: 88.941% \n",
            "[epoch:1, iter:117] Loss: 0.349 | Acc: 89.016% \n",
            "[epoch:1, iter:118] Loss: 0.347 | Acc: 89.069% \n",
            "[epoch:1, iter:119] Loss: 0.345 | Acc: 89.148% \n",
            "[epoch:1, iter:120] Loss: 0.343 | Acc: 89.206% \n",
            "[epoch:1, iter:121] Loss: 0.340 | Acc: 89.295% \n",
            "[epoch:1, iter:122] Loss: 0.338 | Acc: 89.351% \n",
            "[epoch:1, iter:123] Loss: 0.336 | Acc: 89.418% \n",
            "[epoch:1, iter:124] Loss: 0.334 | Acc: 89.485% \n",
            "[epoch:1, iter:125] Loss: 0.332 | Acc: 89.562% \n",
            "[epoch:1, iter:126] Loss: 0.329 | Acc: 89.639% \n",
            "[epoch:1, iter:127] Loss: 0.327 | Acc: 89.696% \n",
            "[epoch:1, iter:128] Loss: 0.326 | Acc: 89.758% \n",
            "[epoch:1, iter:129] Loss: 0.324 | Acc: 89.826% \n",
            "[epoch:1, iter:130] Loss: 0.322 | Acc: 89.862% \n",
            "[epoch:1, iter:131] Loss: 0.320 | Acc: 89.915% \n",
            "[epoch:1, iter:132] Loss: 0.319 | Acc: 89.956% \n",
            "[epoch:1, iter:133] Loss: 0.317 | Acc: 90.020% \n",
            "[epoch:1, iter:134] Loss: 0.315 | Acc: 90.065% \n",
            "[epoch:1, iter:135] Loss: 0.314 | Acc: 90.116% \n",
            "[epoch:1, iter:136] Loss: 0.312 | Acc: 90.165% \n",
            "[epoch:1, iter:137] Loss: 0.310 | Acc: 90.220% \n",
            "[epoch:1, iter:138] Loss: 0.309 | Acc: 90.274% \n",
            "[epoch:1, iter:139] Loss: 0.308 | Acc: 90.316% \n",
            "[epoch:1, iter:140] Loss: 0.306 | Acc: 90.374% \n",
            "[epoch:1, iter:141] Loss: 0.304 | Acc: 90.431% \n",
            "[epoch:1, iter:142] Loss: 0.303 | Acc: 90.487% \n",
            "[epoch:1, iter:143] Loss: 0.301 | Acc: 90.538% \n",
            "[epoch:1, iter:144] Loss: 0.299 | Acc: 90.598% \n",
            "[epoch:1, iter:145] Loss: 0.298 | Acc: 90.641% \n",
            "[epoch:1, iter:146] Loss: 0.296 | Acc: 90.695% \n",
            "[epoch:1, iter:147] Loss: 0.295 | Acc: 90.737% \n",
            "[epoch:1, iter:148] Loss: 0.294 | Acc: 90.789% \n",
            "[epoch:1, iter:149] Loss: 0.292 | Acc: 90.845% \n",
            "[epoch:1, iter:150] Loss: 0.290 | Acc: 90.901% \n",
            "[epoch:1, iter:151] Loss: 0.289 | Acc: 90.951% \n",
            "[epoch:1, iter:152] Loss: 0.287 | Acc: 90.980% \n",
            "[epoch:1, iter:153] Loss: 0.286 | Acc: 91.028% \n",
            "[epoch:1, iter:154] Loss: 0.285 | Acc: 91.066% \n",
            "[epoch:1, iter:155] Loss: 0.283 | Acc: 91.114% \n",
            "[epoch:1, iter:156] Loss: 0.282 | Acc: 91.171% \n",
            "[epoch:1, iter:157] Loss: 0.281 | Acc: 91.207% \n",
            "[epoch:1, iter:158] Loss: 0.279 | Acc: 91.248% \n",
            "[epoch:1, iter:159] Loss: 0.278 | Acc: 91.288% \n",
            "[epoch:1, iter:160] Loss: 0.277 | Acc: 91.333% \n",
            "[epoch:1, iter:161] Loss: 0.276 | Acc: 91.363% \n",
            "[epoch:1, iter:162] Loss: 0.274 | Acc: 91.406% \n",
            "[epoch:1, iter:163] Loss: 0.273 | Acc: 91.449% \n",
            "[epoch:1, iter:164] Loss: 0.272 | Acc: 91.487% \n",
            "[epoch:1, iter:165] Loss: 0.271 | Acc: 91.515% \n",
            "[epoch:1, iter:166] Loss: 0.269 | Acc: 91.547% \n",
            "[epoch:1, iter:167] Loss: 0.268 | Acc: 91.598% \n",
            "[epoch:1, iter:168] Loss: 0.266 | Acc: 91.643% \n",
            "[epoch:1, iter:169] Loss: 0.265 | Acc: 91.679% \n",
            "[epoch:1, iter:170] Loss: 0.264 | Acc: 91.710% \n",
            "[epoch:1, iter:171] Loss: 0.263 | Acc: 91.744% \n",
            "[epoch:1, iter:172] Loss: 0.262 | Acc: 91.788% \n",
            "[epoch:1, iter:173] Loss: 0.261 | Acc: 91.813% \n",
            "[epoch:1, iter:174] Loss: 0.260 | Acc: 91.851% \n",
            "[epoch:1, iter:175] Loss: 0.259 | Acc: 91.888% \n",
            "[epoch:1, iter:176] Loss: 0.258 | Acc: 91.921% \n",
            "[epoch:1, iter:177] Loss: 0.257 | Acc: 91.962% \n",
            "[epoch:1, iter:178] Loss: 0.256 | Acc: 91.994% \n",
            "[epoch:1, iter:179] Loss: 0.255 | Acc: 92.017% \n",
            "[epoch:1, iter:180] Loss: 0.254 | Acc: 92.057% \n",
            "[epoch:1, iter:181] Loss: 0.253 | Acc: 92.084% \n",
            "[epoch:1, iter:182] Loss: 0.252 | Acc: 92.115% \n",
            "[epoch:1, iter:183] Loss: 0.251 | Acc: 92.153% \n",
            "[epoch:1, iter:184] Loss: 0.251 | Acc: 92.175% \n",
            "[epoch:1, iter:185] Loss: 0.250 | Acc: 92.192% \n",
            "[epoch:1, iter:186] Loss: 0.249 | Acc: 92.229% \n",
            "[epoch:1, iter:187] Loss: 0.248 | Acc: 92.254% \n",
            "[epoch:1, iter:188] Loss: 0.247 | Acc: 92.283% \n",
            "[epoch:1, iter:189] Loss: 0.246 | Acc: 92.307% \n",
            "[epoch:1, iter:190] Loss: 0.245 | Acc: 92.331% \n",
            "[epoch:1, iter:191] Loss: 0.244 | Acc: 92.367% \n",
            "[epoch:1, iter:192] Loss: 0.243 | Acc: 92.391% \n",
            "[epoch:1, iter:193] Loss: 0.243 | Acc: 92.418% \n",
            "[epoch:1, iter:194] Loss: 0.242 | Acc: 92.453% \n",
            "[epoch:1, iter:195] Loss: 0.241 | Acc: 92.472% \n",
            "[epoch:1, iter:196] Loss: 0.240 | Acc: 92.494% \n",
            "[epoch:1, iter:197] Loss: 0.240 | Acc: 92.509% \n",
            "[epoch:1, iter:198] Loss: 0.239 | Acc: 92.539% \n",
            "[epoch:1, iter:199] Loss: 0.238 | Acc: 92.560% \n",
            "[epoch:1, iter:200] Loss: 0.237 | Acc: 92.598% \n",
            "[epoch:1, iter:201] Loss: 0.236 | Acc: 92.631% \n",
            "[epoch:1, iter:202] Loss: 0.235 | Acc: 92.655% \n",
            "[epoch:1, iter:203] Loss: 0.234 | Acc: 92.692% \n",
            "[epoch:1, iter:204] Loss: 0.233 | Acc: 92.716% \n",
            "[epoch:1, iter:205] Loss: 0.233 | Acc: 92.736% \n",
            "[epoch:1, iter:206] Loss: 0.232 | Acc: 92.764% \n",
            "[epoch:1, iter:207] Loss: 0.231 | Acc: 92.788% \n",
            "[epoch:1, iter:208] Loss: 0.230 | Acc: 92.815% \n",
            "[epoch:1, iter:209] Loss: 0.229 | Acc: 92.842% \n",
            "[epoch:1, iter:210] Loss: 0.228 | Acc: 92.868% \n",
            "[epoch:1, iter:211] Loss: 0.228 | Acc: 92.891% \n",
            "[epoch:1, iter:212] Loss: 0.227 | Acc: 92.921% \n",
            "[epoch:1, iter:213] Loss: 0.226 | Acc: 92.939% \n",
            "[epoch:1, iter:214] Loss: 0.225 | Acc: 92.969% \n",
            "[epoch:1, iter:215] Loss: 0.224 | Acc: 92.991% \n",
            "[epoch:1, iter:216] Loss: 0.223 | Acc: 93.009% \n",
            "[epoch:1, iter:217] Loss: 0.223 | Acc: 93.026% \n",
            "[epoch:1, iter:218] Loss: 0.222 | Acc: 93.058% \n",
            "[epoch:1, iter:219] Loss: 0.221 | Acc: 93.086% \n",
            "[epoch:1, iter:220] Loss: 0.220 | Acc: 93.107% \n",
            "[epoch:1, iter:221] Loss: 0.220 | Acc: 93.121% \n",
            "[epoch:1, iter:222] Loss: 0.219 | Acc: 93.134% \n",
            "[epoch:1, iter:223] Loss: 0.219 | Acc: 93.151% \n",
            "[epoch:1, iter:224] Loss: 0.218 | Acc: 93.178% \n",
            "[epoch:1, iter:225] Loss: 0.217 | Acc: 93.194% \n",
            "[epoch:1, iter:226] Loss: 0.217 | Acc: 93.214% \n",
            "[epoch:1, iter:227] Loss: 0.216 | Acc: 93.241% \n",
            "[epoch:1, iter:228] Loss: 0.215 | Acc: 93.263% \n",
            "[epoch:1, iter:229] Loss: 0.214 | Acc: 93.286% \n",
            "[epoch:1, iter:230] Loss: 0.214 | Acc: 93.308% \n",
            "[epoch:1, iter:231] Loss: 0.213 | Acc: 93.334% \n",
            "[epoch:1, iter:232] Loss: 0.212 | Acc: 93.363% \n",
            "[epoch:1, iter:233] Loss: 0.211 | Acc: 93.385% \n",
            "[epoch:1, iter:234] Loss: 0.211 | Acc: 93.403% \n",
            "[epoch:1, iter:235] Loss: 0.210 | Acc: 93.424% \n",
            "[epoch:1, iter:236] Loss: 0.209 | Acc: 93.449% \n",
            "[epoch:1, iter:237] Loss: 0.208 | Acc: 93.473% \n",
            "[epoch:1, iter:238] Loss: 0.208 | Acc: 93.494% \n",
            "[epoch:1, iter:239] Loss: 0.207 | Acc: 93.521% \n",
            "[epoch:1, iter:240] Loss: 0.206 | Acc: 93.538% \n",
            "[epoch:1, iter:241] Loss: 0.206 | Acc: 93.562% \n",
            "[epoch:1, iter:242] Loss: 0.205 | Acc: 93.576% \n",
            "[epoch:1, iter:243] Loss: 0.204 | Acc: 93.592% \n",
            "[epoch:1, iter:244] Loss: 0.204 | Acc: 93.619% \n",
            "[epoch:1, iter:245] Loss: 0.203 | Acc: 93.632% \n",
            "[epoch:1, iter:246] Loss: 0.202 | Acc: 93.655% \n",
            "[epoch:1, iter:247] Loss: 0.202 | Acc: 93.677% \n",
            "[epoch:1, iter:248] Loss: 0.201 | Acc: 93.696% \n",
            "[epoch:1, iter:249] Loss: 0.200 | Acc: 93.715% \n",
            "[epoch:1, iter:250] Loss: 0.200 | Acc: 93.738% \n",
            "[epoch:1, iter:251] Loss: 0.199 | Acc: 93.759% \n",
            "[epoch:1, iter:252] Loss: 0.199 | Acc: 93.775% \n",
            "[epoch:1, iter:253] Loss: 0.198 | Acc: 93.799% \n",
            "[epoch:1, iter:254] Loss: 0.197 | Acc: 93.818% \n",
            "[epoch:1, iter:255] Loss: 0.197 | Acc: 93.842% \n",
            "[epoch:1, iter:256] Loss: 0.196 | Acc: 93.860% \n",
            "[epoch:1, iter:257] Loss: 0.196 | Acc: 93.878% \n",
            "[epoch:1, iter:258] Loss: 0.195 | Acc: 93.901% \n",
            "[epoch:1, iter:259] Loss: 0.195 | Acc: 93.919% \n",
            "[epoch:1, iter:260] Loss: 0.194 | Acc: 93.933% \n",
            "[epoch:1, iter:261] Loss: 0.193 | Acc: 93.957% \n",
            "[epoch:1, iter:262] Loss: 0.193 | Acc: 93.977% \n",
            "[epoch:1, iter:263] Loss: 0.192 | Acc: 93.991% \n",
            "[epoch:1, iter:264] Loss: 0.192 | Acc: 94.010% \n",
            "[epoch:1, iter:265] Loss: 0.191 | Acc: 94.030% \n",
            "[epoch:1, iter:266] Loss: 0.191 | Acc: 94.041% \n",
            "[epoch:1, iter:267] Loss: 0.190 | Acc: 94.057% \n",
            "[epoch:1, iter:268] Loss: 0.190 | Acc: 94.068% \n",
            "[epoch:1, iter:269] Loss: 0.189 | Acc: 94.087% \n",
            "[epoch:1, iter:270] Loss: 0.189 | Acc: 94.106% \n",
            "[epoch:1, iter:271] Loss: 0.188 | Acc: 94.128% \n",
            "[epoch:1, iter:272] Loss: 0.187 | Acc: 94.146% \n",
            "[epoch:1, iter:273] Loss: 0.187 | Acc: 94.162% \n",
            "[epoch:1, iter:274] Loss: 0.186 | Acc: 94.175% \n",
            "[epoch:1, iter:275] Loss: 0.186 | Acc: 94.196% \n",
            "[epoch:1, iter:276] Loss: 0.185 | Acc: 94.209% \n",
            "[epoch:1, iter:277] Loss: 0.185 | Acc: 94.221% \n",
            "[epoch:1, iter:278] Loss: 0.184 | Acc: 94.236% \n",
            "[epoch:1, iter:279] Loss: 0.184 | Acc: 94.246% \n",
            "[epoch:1, iter:280] Loss: 0.183 | Acc: 94.261% \n",
            "[epoch:1, iter:281] Loss: 0.183 | Acc: 94.278% \n",
            "[epoch:1, iter:282] Loss: 0.182 | Acc: 94.296% \n",
            "[epoch:1, iter:283] Loss: 0.182 | Acc: 94.313% \n",
            "[epoch:1, iter:284] Loss: 0.182 | Acc: 94.325% \n",
            "[epoch:1, iter:285] Loss: 0.181 | Acc: 94.339% \n",
            "[epoch:1, iter:286] Loss: 0.181 | Acc: 94.348% \n",
            "[epoch:1, iter:287] Loss: 0.180 | Acc: 94.357% \n",
            "[epoch:1, iter:288] Loss: 0.180 | Acc: 94.371% \n",
            "[epoch:1, iter:289] Loss: 0.179 | Acc: 94.391% \n",
            "[epoch:1, iter:290] Loss: 0.179 | Acc: 94.407% \n",
            "[epoch:1, iter:291] Loss: 0.178 | Acc: 94.421% \n",
            "[epoch:1, iter:292] Loss: 0.178 | Acc: 94.430% \n",
            "[epoch:1, iter:293] Loss: 0.178 | Acc: 94.433% \n",
            "[epoch:1, iter:294] Loss: 0.178 | Acc: 94.444% \n",
            "[epoch:1, iter:295] Loss: 0.177 | Acc: 94.460% \n",
            "[epoch:1, iter:296] Loss: 0.177 | Acc: 94.478% \n",
            "[epoch:1, iter:297] Loss: 0.176 | Acc: 94.492% \n",
            "[epoch:1, iter:298] Loss: 0.176 | Acc: 94.508% \n",
            "[epoch:1, iter:299] Loss: 0.175 | Acc: 94.521% \n",
            "[epoch:1, iter:300] Loss: 0.175 | Acc: 94.531% \n",
            "[epoch:1, iter:301] Loss: 0.174 | Acc: 94.547% \n",
            "[epoch:1, iter:302] Loss: 0.174 | Acc: 94.552% \n",
            "[epoch:1, iter:303] Loss: 0.173 | Acc: 94.570% \n",
            "[epoch:1, iter:304] Loss: 0.173 | Acc: 94.588% \n",
            "[epoch:1, iter:305] Loss: 0.173 | Acc: 94.595% \n",
            "[epoch:1, iter:306] Loss: 0.172 | Acc: 94.610% \n",
            "[epoch:1, iter:307] Loss: 0.172 | Acc: 94.625% \n",
            "[epoch:1, iter:308] Loss: 0.172 | Acc: 94.638% \n",
            "[epoch:1, iter:309] Loss: 0.171 | Acc: 94.655% \n",
            "[epoch:1, iter:310] Loss: 0.171 | Acc: 94.662% \n",
            "[epoch:1, iter:311] Loss: 0.171 | Acc: 94.672% \n",
            "[epoch:1, iter:312] Loss: 0.170 | Acc: 94.689% \n",
            "[epoch:1, iter:313] Loss: 0.170 | Acc: 94.698% \n",
            "[epoch:1, iter:314] Loss: 0.169 | Acc: 94.715% \n",
            "[epoch:1, iter:315] Loss: 0.169 | Acc: 94.717% \n",
            "[epoch:1, iter:316] Loss: 0.169 | Acc: 94.732% \n",
            "[epoch:1, iter:317] Loss: 0.169 | Acc: 94.741% \n",
            "[epoch:1, iter:318] Loss: 0.168 | Acc: 94.752% \n",
            "[epoch:1, iter:319] Loss: 0.168 | Acc: 94.764% \n",
            "[epoch:1, iter:320] Loss: 0.167 | Acc: 94.778% \n",
            "[epoch:1, iter:321] Loss: 0.167 | Acc: 94.792% \n",
            "[epoch:1, iter:322] Loss: 0.167 | Acc: 94.805% \n",
            "[epoch:1, iter:323] Loss: 0.166 | Acc: 94.817% \n",
            "[epoch:1, iter:324] Loss: 0.166 | Acc: 94.830% \n",
            "[epoch:1, iter:325] Loss: 0.165 | Acc: 94.841% \n",
            "[epoch:1, iter:326] Loss: 0.165 | Acc: 94.857% \n",
            "[epoch:1, iter:327] Loss: 0.165 | Acc: 94.866% \n",
            "[epoch:1, iter:328] Loss: 0.164 | Acc: 94.877% \n",
            "[epoch:1, iter:329] Loss: 0.164 | Acc: 94.890% \n",
            "[epoch:1, iter:330] Loss: 0.164 | Acc: 94.898% \n",
            "[epoch:1, iter:331] Loss: 0.163 | Acc: 94.911% \n",
            "[epoch:1, iter:332] Loss: 0.163 | Acc: 94.927% \n",
            "[epoch:1, iter:333] Loss: 0.163 | Acc: 94.937% \n",
            "[epoch:1, iter:334] Loss: 0.162 | Acc: 94.950% \n",
            "[epoch:1, iter:335] Loss: 0.162 | Acc: 94.963% \n",
            "[epoch:1, iter:336] Loss: 0.161 | Acc: 94.978% \n",
            "[epoch:1, iter:337] Loss: 0.161 | Acc: 94.990% \n",
            "[epoch:1, iter:338] Loss: 0.161 | Acc: 95.000% \n",
            "[epoch:1, iter:339] Loss: 0.160 | Acc: 95.015% \n",
            "[epoch:1, iter:340] Loss: 0.160 | Acc: 95.030% \n",
            "[epoch:1, iter:341] Loss: 0.159 | Acc: 95.044% \n",
            "[epoch:1, iter:342] Loss: 0.159 | Acc: 95.057% \n",
            "[epoch:1, iter:343] Loss: 0.158 | Acc: 95.067% \n",
            "[epoch:1, iter:344] Loss: 0.158 | Acc: 95.081% \n",
            "[epoch:1, iter:345] Loss: 0.158 | Acc: 95.093% \n",
            "[epoch:1, iter:346] Loss: 0.157 | Acc: 95.107% \n",
            "[epoch:1, iter:347] Loss: 0.157 | Acc: 95.119% \n",
            "[epoch:1, iter:348] Loss: 0.157 | Acc: 95.131% \n",
            "[epoch:1, iter:349] Loss: 0.156 | Acc: 95.145% \n",
            "[epoch:1, iter:350] Loss: 0.156 | Acc: 95.152% \n",
            "[epoch:1, iter:351] Loss: 0.155 | Acc: 95.163% \n",
            "[epoch:1, iter:352] Loss: 0.155 | Acc: 95.177% \n",
            "[epoch:1, iter:353] Loss: 0.155 | Acc: 95.189% \n",
            "[epoch:1, iter:354] Loss: 0.154 | Acc: 95.196% \n",
            "[epoch:1, iter:355] Loss: 0.154 | Acc: 95.207% \n",
            "[epoch:1, iter:356] Loss: 0.154 | Acc: 95.216% \n",
            "[epoch:1, iter:357] Loss: 0.153 | Acc: 95.225% \n",
            "[epoch:1, iter:358] Loss: 0.153 | Acc: 95.232% \n",
            "[epoch:1, iter:359] Loss: 0.153 | Acc: 95.241% \n",
            "[epoch:1, iter:360] Loss: 0.153 | Acc: 95.250% \n",
            "[epoch:1, iter:361] Loss: 0.152 | Acc: 95.258% \n",
            "[epoch:1, iter:362] Loss: 0.152 | Acc: 95.267% \n",
            "[epoch:1, iter:363] Loss: 0.152 | Acc: 95.278% \n",
            "[epoch:1, iter:364] Loss: 0.151 | Acc: 95.289% \n",
            "[epoch:1, iter:365] Loss: 0.151 | Acc: 95.298% \n",
            "[epoch:1, iter:366] Loss: 0.151 | Acc: 95.306% \n",
            "[epoch:1, iter:367] Loss: 0.150 | Acc: 95.317% \n",
            "[epoch:1, iter:368] Loss: 0.150 | Acc: 95.323% \n",
            "[epoch:1, iter:369] Loss: 0.150 | Acc: 95.332% \n",
            "[epoch:1, iter:370] Loss: 0.149 | Acc: 95.340% \n",
            "[epoch:1, iter:371] Loss: 0.149 | Acc: 95.353% \n",
            "[epoch:1, iter:372] Loss: 0.149 | Acc: 95.359% \n",
            "[epoch:1, iter:373] Loss: 0.148 | Acc: 95.367% \n",
            "[epoch:1, iter:374] Loss: 0.148 | Acc: 95.377% \n",
            "[epoch:1, iter:375] Loss: 0.148 | Acc: 95.390% \n",
            "[epoch:1, iter:376] Loss: 0.147 | Acc: 95.398% \n",
            "[epoch:1, iter:377] Loss: 0.147 | Acc: 95.410% \n",
            "[epoch:1, iter:378] Loss: 0.147 | Acc: 95.422% \n",
            "[epoch:1, iter:379] Loss: 0.146 | Acc: 95.430% \n",
            "[epoch:1, iter:380] Loss: 0.146 | Acc: 95.440% \n",
            "[epoch:1, iter:381] Loss: 0.146 | Acc: 95.450% \n",
            "[epoch:1, iter:382] Loss: 0.146 | Acc: 95.460% \n",
            "[epoch:1, iter:383] Loss: 0.145 | Acc: 95.468% \n",
            "[epoch:1, iter:384] Loss: 0.145 | Acc: 95.479% \n",
            "[epoch:1, iter:385] Loss: 0.145 | Acc: 95.489% \n",
            "[epoch:1, iter:386] Loss: 0.144 | Acc: 95.501% \n",
            "[epoch:1, iter:387] Loss: 0.144 | Acc: 95.506% \n",
            "[epoch:1, iter:388] Loss: 0.144 | Acc: 95.516% \n",
            "[epoch:1, iter:389] Loss: 0.144 | Acc: 95.521% \n",
            "[epoch:1, iter:390] Loss: 0.143 | Acc: 95.533% \n",
            "[epoch:1, iter:391] Loss: 0.143 | Acc: 95.542% \n",
            "[epoch:1, iter:392] Loss: 0.143 | Acc: 95.550% \n",
            "[epoch:1, iter:393] Loss: 0.143 | Acc: 95.557% \n",
            "[epoch:1, iter:394] Loss: 0.142 | Acc: 95.566% \n",
            "[epoch:1, iter:395] Loss: 0.142 | Acc: 95.578% \n",
            "[epoch:1, iter:396] Loss: 0.142 | Acc: 95.581% \n",
            "[epoch:1, iter:397] Loss: 0.141 | Acc: 95.584% \n",
            "[epoch:1, iter:398] Loss: 0.141 | Acc: 95.591% \n",
            "[epoch:1, iter:399] Loss: 0.141 | Acc: 95.598% \n",
            "[epoch:1, iter:400] Loss: 0.141 | Acc: 95.605% \n",
            "[epoch:1, iter:401] Loss: 0.141 | Acc: 95.609% \n",
            "[epoch:1, iter:402] Loss: 0.140 | Acc: 95.612% \n",
            "[epoch:1, iter:403] Loss: 0.140 | Acc: 95.621% \n",
            "[epoch:1, iter:404] Loss: 0.140 | Acc: 95.632% \n",
            "[epoch:1, iter:405] Loss: 0.140 | Acc: 95.637% \n",
            "[epoch:1, iter:406] Loss: 0.139 | Acc: 95.643% \n",
            "[epoch:1, iter:407] Loss: 0.139 | Acc: 95.650% \n",
            "[epoch:1, iter:408] Loss: 0.139 | Acc: 95.661% \n",
            "[epoch:1, iter:409] Loss: 0.139 | Acc: 95.666% \n",
            "[epoch:1, iter:410] Loss: 0.139 | Acc: 95.667% \n",
            "[epoch:1, iter:411] Loss: 0.138 | Acc: 95.676% \n",
            "[epoch:1, iter:412] Loss: 0.138 | Acc: 95.682% \n",
            "[epoch:1, iter:413] Loss: 0.138 | Acc: 95.691% \n",
            "[epoch:1, iter:414] Loss: 0.138 | Acc: 95.697% \n",
            "[epoch:1, iter:415] Loss: 0.138 | Acc: 95.695% \n",
            "[epoch:1, iter:416] Loss: 0.137 | Acc: 95.703% \n",
            "[epoch:1, iter:417] Loss: 0.137 | Acc: 95.708% \n",
            "[epoch:1, iter:418] Loss: 0.137 | Acc: 95.707% \n",
            "[epoch:1, iter:419] Loss: 0.137 | Acc: 95.715% \n",
            "[epoch:1, iter:420] Loss: 0.137 | Acc: 95.718% \n",
            "[epoch:1, iter:421] Loss: 0.137 | Acc: 95.724% \n",
            "[epoch:1, iter:422] Loss: 0.136 | Acc: 95.725% \n",
            "[epoch:1, iter:423] Loss: 0.136 | Acc: 95.732% \n",
            "[epoch:1, iter:424] Loss: 0.136 | Acc: 95.742% \n",
            "[epoch:1, iter:425] Loss: 0.136 | Acc: 95.748% \n",
            "[epoch:1, iter:426] Loss: 0.136 | Acc: 95.754% \n",
            "[epoch:1, iter:427] Loss: 0.135 | Acc: 95.761% \n",
            "[epoch:1, iter:428] Loss: 0.135 | Acc: 95.767% \n",
            "[epoch:1, iter:429] Loss: 0.135 | Acc: 95.775% \n",
            "[epoch:1, iter:430] Loss: 0.135 | Acc: 95.778% \n",
            "[epoch:1, iter:431] Loss: 0.134 | Acc: 95.786% \n",
            "[epoch:1, iter:432] Loss: 0.134 | Acc: 95.794% \n",
            "[epoch:1, iter:433] Loss: 0.134 | Acc: 95.803% \n",
            "[epoch:1, iter:434] Loss: 0.134 | Acc: 95.809% \n",
            "[epoch:1, iter:435] Loss: 0.133 | Acc: 95.819% \n",
            "[epoch:1, iter:436] Loss: 0.133 | Acc: 95.827% \n",
            "[epoch:1, iter:437] Loss: 0.133 | Acc: 95.835% \n",
            "[epoch:1, iter:438] Loss: 0.133 | Acc: 95.842% \n",
            "[epoch:1, iter:439] Loss: 0.132 | Acc: 95.852% \n",
            "[epoch:1, iter:440] Loss: 0.132 | Acc: 95.854% \n",
            "[epoch:1, iter:441] Loss: 0.132 | Acc: 95.860% \n",
            "[epoch:1, iter:442] Loss: 0.132 | Acc: 95.866% \n",
            "[epoch:1, iter:443] Loss: 0.132 | Acc: 95.873% \n",
            "[epoch:1, iter:444] Loss: 0.131 | Acc: 95.881% \n",
            "[epoch:1, iter:445] Loss: 0.131 | Acc: 95.881% \n",
            "[epoch:1, iter:446] Loss: 0.131 | Acc: 95.887% \n",
            "[epoch:1, iter:447] Loss: 0.131 | Acc: 95.895% \n",
            "[epoch:1, iter:448] Loss: 0.131 | Acc: 95.904% \n",
            "[epoch:1, iter:449] Loss: 0.131 | Acc: 95.908% \n",
            "[epoch:1, iter:450] Loss: 0.131 | Acc: 95.908% \n",
            "[epoch:1, iter:451] Loss: 0.130 | Acc: 95.915% \n",
            "[epoch:1, iter:452] Loss: 0.130 | Acc: 95.924% \n",
            "[epoch:1, iter:453] Loss: 0.130 | Acc: 95.930% \n",
            "[epoch:1, iter:454] Loss: 0.130 | Acc: 95.937% \n",
            "[epoch:1, iter:455] Loss: 0.129 | Acc: 95.946% \n",
            "[epoch:1, iter:456] Loss: 0.129 | Acc: 95.953% \n",
            "[epoch:1, iter:457] Loss: 0.129 | Acc: 95.959% \n",
            "[epoch:1, iter:458] Loss: 0.129 | Acc: 95.962% \n",
            "[epoch:1, iter:459] Loss: 0.129 | Acc: 95.969% \n",
            "[epoch:1, iter:460] Loss: 0.129 | Acc: 95.973% \n",
            "[epoch:1, iter:461] Loss: 0.128 | Acc: 95.982% \n",
            "[epoch:1, iter:462] Loss: 0.128 | Acc: 95.991% \n",
            "[epoch:1, iter:463] Loss: 0.128 | Acc: 95.993% \n",
            "[epoch:1, iter:464] Loss: 0.128 | Acc: 95.996% \n",
            "[epoch:1, iter:465] Loss: 0.128 | Acc: 96.001% \n",
            "[epoch:1, iter:466] Loss: 0.127 | Acc: 96.010% \n",
            "[epoch:1, iter:467] Loss: 0.127 | Acc: 96.017% \n",
            "[epoch:1, iter:468] Loss: 0.127 | Acc: 96.025% \n",
            "[epoch:1, iter:469] Loss: 0.127 | Acc: 96.030% \n",
            "Waiting Test...\n",
            "Test's ac is: 98.350%\n",
            "\n",
            "Epoch: 2\n",
            "[epoch:2, iter:470] Loss: 0.023 | Acc: 99.219% \n",
            "[epoch:2, iter:471] Loss: 0.015 | Acc: 99.609% \n",
            "[epoch:2, iter:472] Loss: 0.028 | Acc: 99.479% \n",
            "[epoch:2, iter:473] Loss: 0.025 | Acc: 99.609% \n",
            "[epoch:2, iter:474] Loss: 0.033 | Acc: 99.062% \n",
            "[epoch:2, iter:475] Loss: 0.030 | Acc: 99.219% \n",
            "[epoch:2, iter:476] Loss: 0.027 | Acc: 99.330% \n",
            "[epoch:2, iter:477] Loss: 0.028 | Acc: 99.219% \n",
            "[epoch:2, iter:478] Loss: 0.026 | Acc: 99.219% \n",
            "[epoch:2, iter:479] Loss: 0.024 | Acc: 99.297% \n",
            "[epoch:2, iter:480] Loss: 0.024 | Acc: 99.219% \n",
            "[epoch:2, iter:481] Loss: 0.023 | Acc: 99.284% \n",
            "[epoch:2, iter:482] Loss: 0.021 | Acc: 99.339% \n",
            "[epoch:2, iter:483] Loss: 0.022 | Acc: 99.330% \n",
            "[epoch:2, iter:484] Loss: 0.022 | Acc: 99.323% \n",
            "[epoch:2, iter:485] Loss: 0.023 | Acc: 99.219% \n",
            "[epoch:2, iter:486] Loss: 0.024 | Acc: 99.219% \n",
            "[epoch:2, iter:487] Loss: 0.023 | Acc: 99.219% \n",
            "[epoch:2, iter:488] Loss: 0.023 | Acc: 99.219% \n",
            "[epoch:2, iter:489] Loss: 0.023 | Acc: 99.219% \n",
            "[epoch:2, iter:490] Loss: 0.023 | Acc: 99.256% \n",
            "[epoch:2, iter:491] Loss: 0.023 | Acc: 99.219% \n",
            "[epoch:2, iter:492] Loss: 0.023 | Acc: 99.219% \n",
            "[epoch:2, iter:493] Loss: 0.023 | Acc: 99.251% \n",
            "[epoch:2, iter:494] Loss: 0.024 | Acc: 99.250% \n",
            "[epoch:2, iter:495] Loss: 0.024 | Acc: 99.219% \n",
            "[epoch:2, iter:496] Loss: 0.024 | Acc: 99.219% \n",
            "[epoch:2, iter:497] Loss: 0.024 | Acc: 99.247% \n",
            "[epoch:2, iter:498] Loss: 0.023 | Acc: 99.273% \n",
            "[epoch:2, iter:499] Loss: 0.023 | Acc: 99.297% \n",
            "[epoch:2, iter:500] Loss: 0.022 | Acc: 99.320% \n",
            "[epoch:2, iter:501] Loss: 0.022 | Acc: 99.316% \n",
            "[epoch:2, iter:502] Loss: 0.023 | Acc: 99.290% \n",
            "[epoch:2, iter:503] Loss: 0.023 | Acc: 99.311% \n",
            "[epoch:2, iter:504] Loss: 0.024 | Acc: 99.286% \n",
            "[epoch:2, iter:505] Loss: 0.024 | Acc: 99.306% \n",
            "[epoch:2, iter:506] Loss: 0.023 | Acc: 99.324% \n",
            "[epoch:2, iter:507] Loss: 0.023 | Acc: 99.322% \n",
            "[epoch:2, iter:508] Loss: 0.023 | Acc: 99.319% \n",
            "[epoch:2, iter:509] Loss: 0.023 | Acc: 99.336% \n",
            "[epoch:2, iter:510] Loss: 0.023 | Acc: 99.352% \n",
            "[epoch:2, iter:511] Loss: 0.023 | Acc: 99.349% \n",
            "[epoch:2, iter:512] Loss: 0.023 | Acc: 99.364% \n",
            "[epoch:2, iter:513] Loss: 0.023 | Acc: 99.379% \n",
            "[epoch:2, iter:514] Loss: 0.023 | Acc: 99.340% \n",
            "[epoch:2, iter:515] Loss: 0.023 | Acc: 99.355% \n",
            "[epoch:2, iter:516] Loss: 0.023 | Acc: 99.352% \n",
            "[epoch:2, iter:517] Loss: 0.023 | Acc: 99.333% \n",
            "[epoch:2, iter:518] Loss: 0.023 | Acc: 99.314% \n",
            "[epoch:2, iter:519] Loss: 0.023 | Acc: 99.328% \n",
            "[epoch:2, iter:520] Loss: 0.022 | Acc: 99.341% \n",
            "[epoch:2, iter:521] Loss: 0.022 | Acc: 99.339% \n",
            "[epoch:2, iter:522] Loss: 0.023 | Acc: 99.322% \n",
            "[epoch:2, iter:523] Loss: 0.022 | Acc: 99.320% \n",
            "[epoch:2, iter:524] Loss: 0.022 | Acc: 99.332% \n",
            "[epoch:2, iter:525] Loss: 0.022 | Acc: 99.330% \n",
            "[epoch:2, iter:526] Loss: 0.022 | Acc: 99.342% \n",
            "[epoch:2, iter:527] Loss: 0.022 | Acc: 99.353% \n",
            "[epoch:2, iter:528] Loss: 0.022 | Acc: 99.351% \n",
            "[epoch:2, iter:529] Loss: 0.024 | Acc: 99.349% \n",
            "[epoch:2, iter:530] Loss: 0.024 | Acc: 99.360% \n",
            "[epoch:2, iter:531] Loss: 0.024 | Acc: 99.357% \n",
            "[epoch:2, iter:532] Loss: 0.024 | Acc: 99.368% \n",
            "[epoch:2, iter:533] Loss: 0.024 | Acc: 99.377% \n",
            "[epoch:2, iter:534] Loss: 0.024 | Acc: 99.339% \n",
            "[epoch:2, iter:535] Loss: 0.024 | Acc: 99.337% \n",
            "[epoch:2, iter:536] Loss: 0.024 | Acc: 99.335% \n",
            "[epoch:2, iter:537] Loss: 0.024 | Acc: 99.334% \n",
            "[epoch:2, iter:538] Loss: 0.024 | Acc: 99.343% \n",
            "[epoch:2, iter:539] Loss: 0.024 | Acc: 99.353% \n",
            "[epoch:2, iter:540] Loss: 0.024 | Acc: 99.340% \n",
            "[epoch:2, iter:541] Loss: 0.024 | Acc: 99.338% \n",
            "[epoch:2, iter:542] Loss: 0.024 | Acc: 99.336% \n",
            "[epoch:2, iter:543] Loss: 0.024 | Acc: 99.335% \n",
            "[epoch:2, iter:544] Loss: 0.024 | Acc: 99.312% \n",
            "[epoch:2, iter:545] Loss: 0.024 | Acc: 99.311% \n",
            "[epoch:2, iter:546] Loss: 0.024 | Acc: 99.320% \n",
            "[epoch:2, iter:547] Loss: 0.024 | Acc: 99.319% \n",
            "[epoch:2, iter:548] Loss: 0.024 | Acc: 99.318% \n",
            "[epoch:2, iter:549] Loss: 0.024 | Acc: 99.326% \n",
            "[epoch:2, iter:550] Loss: 0.025 | Acc: 99.306% \n",
            "[epoch:2, iter:551] Loss: 0.025 | Acc: 99.295% \n",
            "[epoch:2, iter:552] Loss: 0.025 | Acc: 99.303% \n",
            "[epoch:2, iter:553] Loss: 0.025 | Acc: 99.302% \n",
            "[epoch:2, iter:554] Loss: 0.025 | Acc: 99.311% \n",
            "[epoch:2, iter:555] Loss: 0.025 | Acc: 99.310% \n",
            "[epoch:2, iter:556] Loss: 0.025 | Acc: 99.309% \n",
            "[epoch:2, iter:557] Loss: 0.025 | Acc: 99.299% \n",
            "[epoch:2, iter:558] Loss: 0.026 | Acc: 99.289% \n",
            "[epoch:2, iter:559] Loss: 0.026 | Acc: 99.288% \n",
            "[epoch:2, iter:560] Loss: 0.026 | Acc: 99.287% \n",
            "[epoch:2, iter:561] Loss: 0.026 | Acc: 99.287% \n",
            "[epoch:2, iter:562] Loss: 0.026 | Acc: 99.294% \n",
            "[epoch:2, iter:563] Loss: 0.026 | Acc: 99.294% \n",
            "[epoch:2, iter:564] Loss: 0.026 | Acc: 99.285% \n",
            "[epoch:2, iter:565] Loss: 0.027 | Acc: 99.276% \n",
            "[epoch:2, iter:566] Loss: 0.026 | Acc: 99.275% \n",
            "[epoch:2, iter:567] Loss: 0.026 | Acc: 99.275% \n",
            "[epoch:2, iter:568] Loss: 0.027 | Acc: 99.258% \n",
            "[epoch:2, iter:569] Loss: 0.027 | Acc: 99.258% \n",
            "[epoch:2, iter:570] Loss: 0.027 | Acc: 99.242% \n",
            "[epoch:2, iter:571] Loss: 0.027 | Acc: 99.249% \n",
            "[epoch:2, iter:572] Loss: 0.027 | Acc: 99.249% \n",
            "[epoch:2, iter:573] Loss: 0.027 | Acc: 99.234% \n",
            "[epoch:2, iter:574] Loss: 0.027 | Acc: 99.241% \n",
            "[epoch:2, iter:575] Loss: 0.027 | Acc: 99.241% \n",
            "[epoch:2, iter:576] Loss: 0.027 | Acc: 99.233% \n",
            "[epoch:2, iter:577] Loss: 0.027 | Acc: 99.240% \n",
            "[epoch:2, iter:578] Loss: 0.027 | Acc: 99.233% \n",
            "[epoch:2, iter:579] Loss: 0.027 | Acc: 99.233% \n",
            "[epoch:2, iter:580] Loss: 0.027 | Acc: 99.240% \n",
            "[epoch:2, iter:581] Loss: 0.027 | Acc: 99.226% \n",
            "[epoch:2, iter:582] Loss: 0.027 | Acc: 99.226% \n",
            "[epoch:2, iter:583] Loss: 0.027 | Acc: 99.226% \n",
            "[epoch:2, iter:584] Loss: 0.027 | Acc: 99.232% \n",
            "[epoch:2, iter:585] Loss: 0.026 | Acc: 99.239% \n",
            "[epoch:2, iter:586] Loss: 0.027 | Acc: 99.239% \n",
            "[epoch:2, iter:587] Loss: 0.027 | Acc: 99.245% \n",
            "[epoch:2, iter:588] Loss: 0.026 | Acc: 99.252% \n",
            "[epoch:2, iter:589] Loss: 0.026 | Acc: 99.251% \n",
            "[epoch:2, iter:590] Loss: 0.026 | Acc: 99.251% \n",
            "[epoch:2, iter:591] Loss: 0.026 | Acc: 99.251% \n",
            "[epoch:2, iter:592] Loss: 0.026 | Acc: 99.257% \n",
            "[epoch:2, iter:593] Loss: 0.026 | Acc: 99.257% \n",
            "[epoch:2, iter:594] Loss: 0.026 | Acc: 99.244% \n",
            "[epoch:2, iter:595] Loss: 0.026 | Acc: 99.250% \n",
            "[epoch:2, iter:596] Loss: 0.026 | Acc: 99.256% \n",
            "[epoch:2, iter:597] Loss: 0.026 | Acc: 99.261% \n",
            "[epoch:2, iter:598] Loss: 0.026 | Acc: 99.261% \n",
            "[epoch:2, iter:599] Loss: 0.026 | Acc: 99.261% \n",
            "[epoch:2, iter:600] Loss: 0.026 | Acc: 99.260% \n",
            "[epoch:2, iter:601] Loss: 0.026 | Acc: 99.254% \n",
            "[epoch:2, iter:602] Loss: 0.026 | Acc: 99.260% \n",
            "[epoch:2, iter:603] Loss: 0.026 | Acc: 99.260% \n"
          ]
        }
      ],
      "source": [
        "#train\n",
        "for epoch in range(pre_epoch, EPOCH):\n",
        "    print('\\nEpoch: %d' % (epoch + 1))\n",
        "    net.train()\n",
        "    sum_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        #prepare dataset\n",
        "        length = len(trainloader)\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #forward & backward\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #print ac & loss in each batch\n",
        "        sum_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels.data).cpu().sum()\n",
        "        print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n",
        "              % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
        "\n",
        "    #get the ac with testdataset in each epoch\n",
        "    print('Waiting Test...')\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for data in testloader:\n",
        "            net.eval()\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum()\n",
        "        print('Test\\'s ac is: %.3f%%' % (100 * correct / total))\n",
        "\n",
        "print('Train has finished, total epoch is %d' % EPOCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1eITzaFGOnb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "aiot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}